{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas (libraries) incorporadas (built-in) de Python\n",
    "import os\n",
    "from random import randint\n",
    "# Para cargar solo una vez las bibliotecas detecta si es la primer ejecución del cuaderno\n",
    "try:\n",
    "    os.getegid()\n",
    "    firstrun = False\n",
    "except:\n",
    "    firstrun = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "# Entorno de ejecución\n",
    "\n",
    "# if (firstrun):\n",
    "if('google.colab' in str(get_ipython() ) ):\n",
    "    environment= 'google'\n",
    "else:\n",
    "    import os\n",
    "    if (os.environ.get('PWD')=='/kaggle/working'):\n",
    "        environment= 'kaggle'\n",
    "    else:\n",
    "        environment= 'local'\n",
    "print(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt in /home/vbettachini/bin/jupyter/lib/python3.11/site-packages (8.6.1.post1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt_bindings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mtensorrt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/bin/jupyter/lib/python3.11/site-packages/tensorrt/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# SPDX-FileCopyrightText: Copyright (c) 1993-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorrt_bindings\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorrt_bindings\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt_bindings'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m   get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m pip install tensorrt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mtensorrt\u001b[39;00m\n",
      "File \u001b[0;32m~/bin/jupyter/lib/python3.11/site-packages/tensorrt/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# SPDX-FileCopyrightText: Copyright (c) 1993-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorrt_bindings\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorrt_bindings\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt_bindings'"
     ]
    }
   ],
   "source": [
    "if (environment =='local'):\n",
    "  try:\n",
    "    import tensorrt\n",
    "  except:\n",
    "    ! pip install tensorrt\n",
    "    import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt_bindings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m         get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m pip install tensorrt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m  \u001b[39mimport\u001b[39;00m load_img\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorrt\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# from keras.preprocessing.image import load_img\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m  \u001b[39mimport\u001b[39;00m load_img\n",
      "File \u001b[0;32m~/bin/jupyter/lib/python3.11/site-packages/tensorrt/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# SPDX-FileCopyrightText: Copyright (c) 1993-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorrt_bindings\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorrt_bindings\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt_bindings'"
     ]
    }
   ],
   "source": [
    "if (firstrun):\n",
    "    try:\n",
    "        from tensorflow.keras.utils  import load_img\n",
    "    except:\n",
    "        ! pip install tensorflow\n",
    "        from tensorflow.keras.utils  import load_img\n",
    "\n",
    "# from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils  import load_img\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué `tensorflow.keras` y `keras`?  \n",
    "[Stack overflow | keras vs. tensorflow.python.keras - which one to use?](https://stackoverflow.com/questions/48893528/keras-vs-tensorflow-python-keras-which-one-to-use)\n",
    "> tensorflow.python.keras is just a bundle of keras with a single backend inside tensorflow package. This allows you to start using keras by installing just pip install tensorflow.\n",
    "> \n",
    "> keras package contains full keras library with three supported backends: tensorflow, theano and CNTK. If you even wish to switch between backends, you should choose keras package. This approach is also more flexible because it allows to install keras updates independently from tensorflow (which may not be easy to update, for example, because the next version may require a different version of CUDA driver) or vice versa. For this reason, I prefer to install keras as another package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de muestra de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio base ( cambiar según el sistema de archivos de cada uno)\n",
    "# if (firstrun):\n",
    "if( environment== 'local' ):\n",
    "    # system_path = \"C:/Users/vanes/Documents/UBA/2do_cuatrimestre/DMCyT/TP/\"\n",
    "    system_path = '/home/vbettachini/documents/universitet/FCEyN/maestríaDatos/cienciaTecnología/'\n",
    "elif( ( environment== 'google' ) ): \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    system_path = \"/content/drive/MyDrive/maestría/cienciaTecnología/\"\n",
    "elif( ( environment== 'kaggle' ) )  :\n",
    "    a= 1\n",
    "\n",
    "# Directorio del dataset\n",
    "dataset_path = system_path + \"tp1_dmcyt2023/datasets/Rice_Image_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path a subset imágenes generado por `random_sample_rice_images.ipynb`\n",
    "image_path = dataset_path + \"/random_sample_rice_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "/home/vbettachini/documents/universitet/FCEyN/maestríaDatos/cienciaTecnología/tp1_dmcyt2023/datasets/Rice_Image_Dataset/random_sample_rice_images/Arborio (1002).jpg\n"
     ]
    }
   ],
   "source": [
    "path = sorted(\n",
    "  [\n",
    "    os.path.join(image_path, file)\n",
    "    for file in os.listdir(image_path )\n",
    "    if file.endswith('.jpg')\n",
    "  ]\n",
    ")\n",
    "print(len(path))\n",
    "print(path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # levanta imagen como array 224x224\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convierte img a numpy array (originalmente es 'PIL.Image.Image')\n",
    "    img = np.array(img)\n",
    "    # reshape para tener formato necesario para el modelo (num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3)\n",
    "    # prepara imagen para modelo (función de keras)\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # extrae features\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(lista, model):\n",
    "    datays = {}\n",
    "    for i in lista:\n",
    "      featuress = extract_features(i, model)\n",
    "      datays[i] = featuress\n",
    "    # lista de filenames\n",
    "    filenmss = np.array(list(datays.keys()))\n",
    "\n",
    "    # lista de features\n",
    "    featsss = np.array(list(datays.values()))\n",
    "\n",
    "    # reshape 4096 features por el número de imagens\n",
    "    print(featsss.shape)\n",
    "    featsss = featsss.reshape(-1,4096)\n",
    "    return filenmss, featsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 12:26:27.189892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-27 12:26:27.571672: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-09-27 12:26:28.011507: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-27 12:26:28.530439: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-27 12:26:28.751752: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-27 12:26:31.192211: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "if (firstrun):\n",
    "    try:\n",
    "        from keras.models import Model\n",
    "    except:\n",
    "        ! pip install keras\n",
    "        from keras.models import Model\n",
    "\n",
    "from keras.models import Model\n",
    "# Tensorflow model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (firstrun):\n",
    "  try:\n",
    "    import numpy as np\n",
    "  except:\n",
    "    ! pip install numpy\n",
    "    import numpy as np\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "## Levanta archivos y extrae features\n",
    "names, feat = preprocess(path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(image_path + '/vgg16output.npz', feat = feat, names = names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
