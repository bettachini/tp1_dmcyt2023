
@online{kamienkowski_curso_2023,
	title = {Curso: Data Mining en Ciencia y Tecnología},
	url = {https://datamining.dc.uba.ar/campus/course/view.php?id=37},
	author = {Kamienkowski, Juan A.},
	urldate = {2023-09-12},
	date = {2023},
	file = {Curso\: Data Mining en Ciencia y Tecnología:/home/vbettachini/storage/Zotero/storage/HYK85YW9/view.html:text/html},
}

@online{belitskaya_flower_2020,
	title = {Flower Color Images},
	url = {https://www.kaggle.com/datasets/olgabelitskaya/flower-color-images},
	abstract = {Flower Color Images, Set for Classification},
	author = {Belitskaya, Olga},
	urldate = {2023-09-12},
	date = {2020},
	langid = {english},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/SGQIZ4NR/flower-color-images.html:text/html},
}

@online{taskesen_pca_2020,
	title = {{PCA} — clustimage clustimage documentation},
	url = {https://erdogant.github.io/clustimage/pages/html/Feature%20Extraction.html},
	author = {Taskesen, E.},
	urldate = {2023-09-12},
	date = {2020},
	file = {PCA — clustimage clustimage documentation:/home/vbettachini/storage/Zotero/storage/VBDD4LP4/Feature Extraction.html:text/html},
}

@online{noauthor_opencv_nodate,
	title = {{OpenCV}: Changing the contrast and brightness of an image!},
	url = {https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html},
	urldate = {2023-09-12},
	file = {OpenCV\: Changing the contrast and brightness of an image!:/home/vbettachini/storage/Zotero/storage/V3GCU5B3/tutorial_basic_linear_transform.html:text/html},
}

@online{noauthor_standard_1996,
	title = {A Standard Default Color Space for the Internet - {sRGB}},
	url = {https://www.w3.org/Graphics/Color/sRGB},
	titleaddon = {World Wide Web Consortium},
	urldate = {2023-09-12},
	date = {1996-11-05},
	file = {A Standard Default Color Space for the Internet - sRGB:/home/vbettachini/storage/Zotero/storage/76SJYU7X/sRGB.html:text/html},
}

@online{noauthor_opencv_nodate-1,
	title = {{OpenCV}: Image Filtering},
	url = {https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html},
	urldate = {2023-09-13},
	file = {OpenCV\: Image Filtering:/home/vbettachini/storage/Zotero/storage/CDS5JWIZ/group__imgproc__filter.html:text/html},
}

@online{noauthor_api_nodate,
	title = {{API} References — clustimage clustimage documentation},
	url = {https://erdogant.github.io/clustimage/pages/html/clustimage.clustimage.html#clustimage.clustimage.Clustimage.fit_transform},
	urldate = {2023-09-15},
	file = {API References — clustimage clustimage documentation:/home/vbettachini/storage/Zotero/storage/VT4V4ZZG/clustimage.clustimage.html:text/html},
}

@misc{simonyan_very_2015,
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution ﬁlters, which shows that a signiﬁcant improvement on the prior-art conﬁgurations can be achieved by pushing the depth to 16–19 weight layers. These ﬁndings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the ﬁrst and the second places in the localisation and classiﬁcation tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	number = {{arXiv}:1409.1556},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2023-10-13},
	date = {2015-04-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:/home/vbettachini/storage/Zotero/storage/H8XF5PPH/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf},
}

@online{team_keras_nodate,
	title = {Keras documentation: {VGG}16 and {VGG}19},
	url = {https://keras.io/api/applications/vgg/},
	shorttitle = {Keras documentation},
	abstract = {Keras documentation},
	author = {Team, Keras},
	urldate = {2023-10-13},
	langid = {english},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/2MBSPZTK/vgg.html:text/html},
}

@article{koklu_classification_2021,
	title = {Classification of rice varieties with deep learning methods},
	volume = {187},
	issn = {01681699},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169921003021},
	doi = {10.1016/j.compag.2021.106285},
	abstract = {Rice, which is among the most widely produced grain products worldwide, has many genetic varieties. These varieties are separated from each other due to some of their features. These are usually features such as texture, shape, and color. With these features that distinguish rice varieties, it is possible to classify and evaluate the quality of seeds. In this study, Arborio, Basmati, Ipsala, Jasmine and Karacadag, which are five different varieties of rice often grown in Turkey, were used. A total of 75,000 grain images, 15,000 from each of these varieties, are included in the dataset. A second dataset with 106 features including 12 morphological, 4 shape and 90 color features obtained from these images was used. Models were created by using Artificial Neural Network ({ANN}) and Deep Neural Network ({DNN}) algorithms for the feature dataset and by using the Convolutional Neural Network ({CNN}) algorithm for the image dataset, and classification processes were performed. Statistical results of sensitivity, specificity, prediction, F1 score, accuracy, false positive rate and false negative rate were calcu­ lated using the confusion matrix values of the models and the results of each model were given in tables. Classification successes from the models were achieved as 99.87\% for {ANN}, 99.95\% for {DNN} and 100\% for {CNN}. With the results, it is seen that the models used in the study in the classification of rice varieties can be applied successfully in this field.},
	pages = {106285},
	journaltitle = {Computers and Electronics in Agriculture},
	shortjournal = {Computers and Electronics in Agriculture},
	author = {Koklu, Murat and Cinar, Ilkay and Taspinar, Yavuz Selim},
	urldate = {2023-10-16},
	date = {2021-08},
	langid = {english},
	file = {Koklu et al. - 2021 - Classification of rice varieties with deep learnin.pdf:/home/vbettachini/storage/Zotero/storage/TM684H65/Koklu et al. - 2021 - Classification of rice varieties with deep learnin.pdf:application/pdf},
}

@online{murat_kuklu_rice_2022,
	title = {Rice Image Dataset},
	url = {https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset},
	abstract = {Five different Rice Image Dataset. Arborio, Basmati, Ipsala, Jasmine, Karacadag},
	author = {{Murat Kuklu}},
	urldate = {2023-10-16},
	date = {2022},
	langid = {english},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/TXR2FUXR/rice-image-dataset.html:text/html},
}

@article{knyazev_toward_2001,
	title = {Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method},
	volume = {23},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827500366124},
	doi = {10.1137/S1064827500366124},
	shorttitle = {Toward the Optimal Preconditioned Eigensolver},
	abstract = {We describe new algorithms of the locally optimal block preconditioned conjugate gradient ({LOBPCG}) method for symmetric eigenvalue problems, based on a local optimization of a three-term recurrence, and suggest several other new methods. To be able to compare numerically diﬀerent methods in the class, with diﬀerent preconditioners, we propose a common system of model tests, using random preconditioners and initial guesses. As the “ideal” control algorithm, we advocate the standard preconditioned conjugate gradient method for ﬁnding an eigenvector as an element of the null-space of the corresponding homogeneous system of linear equations under the assumption that the eigenvalue is known. We recommend that every new preconditioned eigensolver be compared with this “ideal” algorithm on our model test problems in terms of the speed of convergence, costs of every iteration, and memory requirements. We provide such comparison for our {LOBPCG} method. Numerical results establish that our algorithm is practically as eﬃcient as the “ideal” algorithm when the same preconditioner is used in both methods. We also show numerically that the {LOBPCG} method provides approximations to ﬁrst eigenpairs of about the same quality as those by the much more expensive global optimization method on the same generalized block Krylov subspace. We propose a new version of block Davidson’s method as a generalization of the {LOBPCG} method. Finally, direct numerical comparisons with the Jacobi–Davidson method show that our method is more robust and converges almost two times faster.},
	pages = {517--541},
	number = {2},
	journaltitle = {{SIAM} Journal on Scientific Computing},
	shortjournal = {{SIAM} J. Sci. Comput.},
	author = {Knyazev, Andrew V.},
	urldate = {2023-10-16},
	date = {2001-01},
	langid = {english},
	file = {Knyazev - 2001 - Toward the Optimal Preconditioned Eigensolver Loc.pdf:/home/vbettachini/storage/Zotero/storage/V3Q27Y2M/Knyazev - 2001 - Toward the Optimal Preconditioned Eigensolver Loc.pdf:application/pdf},
}

@article{tagliazucchi_large-scale_2013,
	title = {Large-scale brain functional modularity is reflected in slow electroencephalographic rhythms across the human non-rapid eye movement sleep cycle},
	volume = {70},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811913000128},
	doi = {10.1016/j.neuroimage.2012.12.073},
	abstract = {Large-scale brain functional networks (measured with functional magnetic resonance imaging, {fMRI}) are organized into separated but interacting modules, an architecture supporting the integration of distinct dynamical processes. In this work we study how the aforementioned modular architecture changes with the progressive loss of vigilance occurring in the descent to deep sleep and we examine the relationship between the ensuing slow electroencephalographic rhythms and large-scale network modularity as measured with {fMRI}.},
	pages = {327--339},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Tagliazucchi, Enzo and Von Wegner, Frederic and Morzelewski, Astrid and Brodbeck, Verena and Borisov, Sergey and Jahnke, Kolja and Laufs, Helmut},
	urldate = {2023-11-01},
	date = {2013-04},
	langid = {english},
	file = {Tagliazucchi et al. - 2013 - Large-scale brain functional modularity is reflect.pdf:/home/vbettachini/storage/Zotero/storage/BA382RSE/Tagliazucchi et al. - 2013 - Large-scale brain functional modularity is reflect.pdf:application/pdf},
}

@article{tzourio-mazoyer_automated_2002,
	title = {Automated Anatomical Labeling of Activations in {SPM} Using a Macroscopic Anatomical Parcellation of the {MNI} {MRI} Single-Subject Brain},
	volume = {15},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811901909784},
	doi = {10.1006/nimg.2001.0978},
	pages = {273--289},
	number = {1},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Tzourio-Mazoyer, N. and Landeau, B. and Papathanassiou, D. and Crivello, F. and Etard, O. and Delcroix, N. and Mazoyer, B. and Joliot, M.},
	urldate = {2023-11-01},
	date = {2002-01},
	langid = {english},
	file = {Tzourio-Mazoyer et al. - 2002 - Automated Anatomical Labeling of Activations in SP.pdf:/home/vbettachini/storage/Zotero/storage/ZYZ5ZT4G/Tzourio-Mazoyer et al. - 2002 - Automated Anatomical Labeling of Activations in SP.pdf:application/pdf},
}

@inproceedings{hagberg_exploring_2008,
	location = {Pasadena, {CA} {USA}},
	title = {Exploring Network Structure, Dynamics, and Function using {NetworkX}},
	url = {https://conference.scipy.org/proceedings/SciPy2008/paper_2/},
	eventtitle = {{SciPy} 2008},
	pages = {11--15},
	booktitle = {Proceedings of the 7th Python in Science Conference ({SciPy} 2008)},
	author = {Hagberg, Aric A and Schult, Daniel A and Swart, Pieter J},
	date = {2008-08},
	langid = {english},
	file = {Hagberg et al. - 2008 - Exploring Network Structure, Dynamics, and Functio.pdf:/home/vbettachini/storage/Zotero/storage/HU4ESVBF/Hagberg et al. - 2008 - Exploring Network Structure, Dynamics, and Functio.pdf:application/pdf},
}

@book{albert-laszlo_barabasi_network_2016,
	title = {Network Science},
	rights = {Creative Commons Attribution-{NonCommercial} 3.0 Unported License.},
	isbn = {978-1-107-07626-6},
	url = {http://networksciencebook.com/},
	abstract = {Networks are everywhere, from the internet, to social networks, and the genetic networks that determine our biological existence. Illustrated throughout in full colour, this pioneering textbook, spanning a wide range of topics from physics to computer science, engineering, economics and the social sciences, introduces network science to an interdisciplinary audience. From the origins of the six degrees of separation to explaining why networks are robust to random failures, the author explores how viruses like Ebola and H1N1 spread, and why it is that our friends have more friends than we do. Using numerous real-world examples, this innovatively designed text includes clear delineation between undergraduate and graduate level material. The mathematical formulas and derivations are included within Advanced Topics sections, enabling use at a range of levels. Extensive online resources, including films and software for network analysis, make this a multifaceted companion for anyone with an interest in network science.

    Uses an interdisciplinary perspective with examples from across scientific and social science fields, making it accessible to students of various subjects
    Supported by a fully interactive online version with numerous multimedia resources to assist students in their learning
    The first textbook of its kind in a rapidly expanding field},
	pagetotal = {456},
	publisher = {Cambridge University Press},
	author = {{Albert-László Barabási}},
	urldate = {2023-11-03},
	date = {2016-07},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/ZM4ITUJA/networksciencebook.com.html:text/html},
}

@article{ek_global_2015,
	title = {Global efficiency of graphs},
	volume = {12},
	issn = {0972-8600, 2543-3474},
	url = {https://www.tandfonline.com/doi/full/10.1016/j.akcej.2015.06.001},
	doi = {10.1016/j.akcej.2015.06.001},
	pages = {1--13},
	number = {1},
	journaltitle = {{AKCE} International Journal of Graphs and Combinatorics},
	shortjournal = {{AKCE} International Journal of Graphs and Combinatorics},
	author = {Ek, Bryan and {VerSchneider}, Caitlin and Narayan, Darren A.},
	urldate = {2023-11-05},
	date = {2015-07-01},
	langid = {english},
	file = {Ek et al. - 2015 - Global efficiency of graphs.pdf:/home/vbettachini/storage/Zotero/storage/3MJ3V4LL/Ek et al. - 2015 - Global efficiency of graphs.pdf:application/pdf},
}
