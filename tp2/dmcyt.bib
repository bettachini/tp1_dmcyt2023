
@online{kamienkowski_curso_2023,
	title = {Curso: Data Mining en Ciencia y Tecnología},
	url = {https://datamining.dc.uba.ar/campus/course/view.php?id=37},
	author = {Kamienkowski, Juan A.},
	urldate = {2023-09-12},
	date = {2023},
	file = {Curso\: Data Mining en Ciencia y Tecnología:/home/vbettachini/storage/Zotero/storage/HYK85YW9/view.html:text/html},
}

@online{belitskaya_flower_2020,
	title = {Flower Color Images},
	url = {https://www.kaggle.com/datasets/olgabelitskaya/flower-color-images},
	abstract = {Flower Color Images, Set for Classification},
	author = {Belitskaya, Olga},
	urldate = {2023-09-12},
	date = {2020},
	langid = {english},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/SGQIZ4NR/flower-color-images.html:text/html},
}

@online{taskesen_pca_2020,
	title = {{PCA} — clustimage clustimage documentation},
	url = {https://erdogant.github.io/clustimage/pages/html/Feature%20Extraction.html},
	author = {Taskesen, E.},
	urldate = {2023-09-12},
	date = {2020},
	file = {PCA — clustimage clustimage documentation:/home/vbettachini/storage/Zotero/storage/VBDD4LP4/Feature Extraction.html:text/html},
}

@online{noauthor_opencv_nodate,
	title = {{OpenCV}: Changing the contrast and brightness of an image!},
	url = {https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html},
	urldate = {2023-09-12},
	file = {OpenCV\: Changing the contrast and brightness of an image!:/home/vbettachini/storage/Zotero/storage/V3GCU5B3/tutorial_basic_linear_transform.html:text/html},
}

@online{noauthor_standard_1996,
	title = {A Standard Default Color Space for the Internet - {sRGB}},
	url = {https://www.w3.org/Graphics/Color/sRGB},
	titleaddon = {World Wide Web Consortium},
	urldate = {2023-09-12},
	date = {1996-11-05},
	file = {A Standard Default Color Space for the Internet - sRGB:/home/vbettachini/storage/Zotero/storage/76SJYU7X/sRGB.html:text/html},
}

@online{noauthor_opencv_nodate-1,
	title = {{OpenCV}: Image Filtering},
	url = {https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html},
	urldate = {2023-09-13},
	file = {OpenCV\: Image Filtering:/home/vbettachini/storage/Zotero/storage/CDS5JWIZ/group__imgproc__filter.html:text/html},
}

@online{noauthor_api_nodate,
	title = {{API} References — clustimage clustimage documentation},
	url = {https://erdogant.github.io/clustimage/pages/html/clustimage.clustimage.html#clustimage.clustimage.Clustimage.fit_transform},
	urldate = {2023-09-15},
	file = {API References — clustimage clustimage documentation:/home/vbettachini/storage/Zotero/storage/VT4V4ZZG/clustimage.clustimage.html:text/html},
}

@misc{simonyan_very_2015,
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution ﬁlters, which shows that a signiﬁcant improvement on the prior-art conﬁgurations can be achieved by pushing the depth to 16–19 weight layers. These ﬁndings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the ﬁrst and the second places in the localisation and classiﬁcation tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	number = {{arXiv}:1409.1556},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2023-10-13},
	date = {2015-04-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:/home/vbettachini/storage/Zotero/storage/H8XF5PPH/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf},
}

@online{team_keras_nodate,
	title = {Keras documentation: {VGG}16 and {VGG}19},
	url = {https://keras.io/api/applications/vgg/},
	shorttitle = {Keras documentation},
	abstract = {Keras documentation},
	author = {Team, Keras},
	urldate = {2023-10-13},
	langid = {english},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/2MBSPZTK/vgg.html:text/html},
}

@article{koklu_classification_2021,
	title = {Classification of rice varieties with deep learning methods},
	volume = {187},
	issn = {01681699},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169921003021},
	doi = {10.1016/j.compag.2021.106285},
	abstract = {Rice, which is among the most widely produced grain products worldwide, has many genetic varieties. These varieties are separated from each other due to some of their features. These are usually features such as texture, shape, and color. With these features that distinguish rice varieties, it is possible to classify and evaluate the quality of seeds. In this study, Arborio, Basmati, Ipsala, Jasmine and Karacadag, which are five different varieties of rice often grown in Turkey, were used. A total of 75,000 grain images, 15,000 from each of these varieties, are included in the dataset. A second dataset with 106 features including 12 morphological, 4 shape and 90 color features obtained from these images was used. Models were created by using Artificial Neural Network ({ANN}) and Deep Neural Network ({DNN}) algorithms for the feature dataset and by using the Convolutional Neural Network ({CNN}) algorithm for the image dataset, and classification processes were performed. Statistical results of sensitivity, specificity, prediction, F1 score, accuracy, false positive rate and false negative rate were calcu­ lated using the confusion matrix values of the models and the results of each model were given in tables. Classification successes from the models were achieved as 99.87\% for {ANN}, 99.95\% for {DNN} and 100\% for {CNN}. With the results, it is seen that the models used in the study in the classification of rice varieties can be applied successfully in this field.},
	pages = {106285},
	journaltitle = {Computers and Electronics in Agriculture},
	shortjournal = {Computers and Electronics in Agriculture},
	author = {Koklu, Murat and Cinar, Ilkay and Taspinar, Yavuz Selim},
	urldate = {2023-10-16},
	date = {2021-08},
	langid = {english},
	file = {Koklu et al. - 2021 - Classification of rice varieties with deep learnin.pdf:/home/vbettachini/storage/Zotero/storage/TM684H65/Koklu et al. - 2021 - Classification of rice varieties with deep learnin.pdf:application/pdf},
}

@online{murat_kuklu_rice_2022,
	title = {Rice Image Dataset},
	url = {https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset},
	abstract = {Five different Rice Image Dataset. Arborio, Basmati, Ipsala, Jasmine, Karacadag},
	author = {{Murat Kuklu}},
	urldate = {2023-10-16},
	date = {2022},
	langid = {english},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/TXR2FUXR/rice-image-dataset.html:text/html},
}

@article{knyazev_toward_2001,
	title = {Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method},
	volume = {23},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827500366124},
	doi = {10.1137/S1064827500366124},
	shorttitle = {Toward the Optimal Preconditioned Eigensolver},
	abstract = {We describe new algorithms of the locally optimal block preconditioned conjugate gradient ({LOBPCG}) method for symmetric eigenvalue problems, based on a local optimization of a three-term recurrence, and suggest several other new methods. To be able to compare numerically diﬀerent methods in the class, with diﬀerent preconditioners, we propose a common system of model tests, using random preconditioners and initial guesses. As the “ideal” control algorithm, we advocate the standard preconditioned conjugate gradient method for ﬁnding an eigenvector as an element of the null-space of the corresponding homogeneous system of linear equations under the assumption that the eigenvalue is known. We recommend that every new preconditioned eigensolver be compared with this “ideal” algorithm on our model test problems in terms of the speed of convergence, costs of every iteration, and memory requirements. We provide such comparison for our {LOBPCG} method. Numerical results establish that our algorithm is practically as eﬃcient as the “ideal” algorithm when the same preconditioner is used in both methods. We also show numerically that the {LOBPCG} method provides approximations to ﬁrst eigenpairs of about the same quality as those by the much more expensive global optimization method on the same generalized block Krylov subspace. We propose a new version of block Davidson’s method as a generalization of the {LOBPCG} method. Finally, direct numerical comparisons with the Jacobi–Davidson method show that our method is more robust and converges almost two times faster.},
	pages = {517--541},
	number = {2},
	journaltitle = {{SIAM} Journal on Scientific Computing},
	shortjournal = {{SIAM} J. Sci. Comput.},
	author = {Knyazev, Andrew V.},
	urldate = {2023-10-16},
	date = {2001-01},
	langid = {english},
	file = {Knyazev - 2001 - Toward the Optimal Preconditioned Eigensolver Loc.pdf:/home/vbettachini/storage/Zotero/storage/V3Q27Y2M/Knyazev - 2001 - Toward the Optimal Preconditioned Eigensolver Loc.pdf:application/pdf},
}

@article{tagliazucchi_large-scale_2013,
	title = {Large-scale brain functional modularity is reflected in slow electroencephalographic rhythms across the human non-rapid eye movement sleep cycle},
	volume = {70},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811913000128},
	doi = {10.1016/j.neuroimage.2012.12.073},
	abstract = {Large-scale brain functional networks (measured with functional magnetic resonance imaging, {fMRI}) are organized into separated but interacting modules, an architecture supporting the integration of distinct dynamical processes. In this work we study how the aforementioned modular architecture changes with the progressive loss of vigilance occurring in the descent to deep sleep and we examine the relationship between the ensuing slow electroencephalographic rhythms and large-scale network modularity as measured with {fMRI}.},
	pages = {327--339},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Tagliazucchi, Enzo and Von Wegner, Frederic and Morzelewski, Astrid and Brodbeck, Verena and Borisov, Sergey and Jahnke, Kolja and Laufs, Helmut},
	urldate = {2023-11-01},
	date = {2013-04},
	langid = {english},
	file = {Tagliazucchi et al. - 2013 - Large-scale brain functional modularity is reflect.pdf:/home/vbettachini/storage/Zotero/storage/BA382RSE/Tagliazucchi et al. - 2013 - Large-scale brain functional modularity is reflect.pdf:application/pdf},
}

@article{tzourio-mazoyer_automated_2002,
	title = {Automated Anatomical Labeling of Activations in {SPM} Using a Macroscopic Anatomical Parcellation of the {MNI} {MRI} Single-Subject Brain},
	volume = {15},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811901909784},
	doi = {10.1006/nimg.2001.0978},
	pages = {273--289},
	number = {1},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Tzourio-Mazoyer, N. and Landeau, B. and Papathanassiou, D. and Crivello, F. and Etard, O. and Delcroix, N. and Mazoyer, B. and Joliot, M.},
	urldate = {2023-11-01},
	date = {2002-01},
	langid = {english},
	file = {Tzourio-Mazoyer et al. - 2002 - Automated Anatomical Labeling of Activations in SP.pdf:/home/vbettachini/storage/Zotero/storage/ZYZ5ZT4G/Tzourio-Mazoyer et al. - 2002 - Automated Anatomical Labeling of Activations in SP.pdf:application/pdf},
}

@inproceedings{hagberg_exploring_2008,
	location = {Pasadena, {CA} {USA}},
	title = {Exploring Network Structure, Dynamics, and Function using {NetworkX}},
	url = {https://conference.scipy.org/proceedings/SciPy2008/paper_2/},
	eventtitle = {{SciPy} 2008},
	pages = {11--15},
	booktitle = {Proceedings of the 7th Python in Science Conference ({SciPy} 2008)},
	author = {Hagberg, Aric A and Schult, Daniel A and Swart, Pieter J},
	date = {2008-08},
	langid = {english},
	file = {Hagberg et al. - 2008 - Exploring Network Structure, Dynamics, and Functio.pdf:/home/vbettachini/storage/Zotero/storage/HU4ESVBF/Hagberg et al. - 2008 - Exploring Network Structure, Dynamics, and Functio.pdf:application/pdf},
}

@book{albert-laszlo_barabasi_network_2016,
	title = {Network Science},
	rights = {Creative Commons Attribution-{NonCommercial} 3.0 Unported License.},
	isbn = {978-1-107-07626-6},
	url = {http://networksciencebook.com/},
	abstract = {Networks are everywhere, from the internet, to social networks, and the genetic networks that determine our biological existence. Illustrated throughout in full colour, this pioneering textbook, spanning a wide range of topics from physics to computer science, engineering, economics and the social sciences, introduces network science to an interdisciplinary audience. From the origins of the six degrees of separation to explaining why networks are robust to random failures, the author explores how viruses like Ebola and H1N1 spread, and why it is that our friends have more friends than we do. Using numerous real-world examples, this innovatively designed text includes clear delineation between undergraduate and graduate level material. The mathematical formulas and derivations are included within Advanced Topics sections, enabling use at a range of levels. Extensive online resources, including films and software for network analysis, make this a multifaceted companion for anyone with an interest in network science.

    Uses an interdisciplinary perspective with examples from across scientific and social science fields, making it accessible to students of various subjects
    Supported by a fully interactive online version with numerous multimedia resources to assist students in their learning
    The first textbook of its kind in a rapidly expanding field},
	pagetotal = {456},
	publisher = {Cambridge University Press},
	author = {{Albert-László Barabási}},
	urldate = {2023-11-03},
	date = {2016-07},
	file = {Snapshot:/home/vbettachini/storage/Zotero/storage/ZM4ITUJA/networksciencebook.com.html:text/html},
}

@article{ek_global_2015,
	title = {Global efficiency of graphs},
	volume = {12},
	issn = {0972-8600, 2543-3474},
	url = {https://www.tandfonline.com/doi/full/10.1016/j.akcej.2015.06.001},
	doi = {10.1016/j.akcej.2015.06.001},
	pages = {1--13},
	number = {1},
	journaltitle = {{AKCE} International Journal of Graphs and Combinatorics},
	shortjournal = {{AKCE} International Journal of Graphs and Combinatorics},
	author = {Ek, Bryan and {VerSchneider}, Caitlin and Narayan, Darren A.},
	urldate = {2023-11-05},
	date = {2015-07-01},
	langid = {english},
	file = {Ek et al. - 2015 - Global efficiency of graphs.pdf:/home/vbettachini/storage/Zotero/storage/3MJ3V4LL/Ek et al. - 2015 - Global efficiency of graphs.pdf:application/pdf},
}

@incollection{patel_physiology_2023,
	location = {Treasure Island ({FL})},
	title = {Physiology, Sleep Stages},
	rights = {Copyright © 2023, {StatPearls} Publishing {LLC}.},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK526132/},
	abstract = {The human body cycles through two phases of sleep, (1) rapid eye movement ({REM}) and (2) non-rapid eye movement ({NREM}) sleep, which is further divided into three stages, N1-N3. Each phase and stage of sleep includes variations in muscle tone, brain wave patterns, and eye movements. The body cycles through all of these stages approximately 4 to 6 times each night, averaging 90 minutes for each cycle. This article will discuss the progression of the sleep stages and the unique features associated with each.},
	booktitle = {{StatPearls}},
	publisher = {{StatPearls} Publishing},
	author = {Patel, Aakash K. and Reddy, Vamsi and Shumway, Karlie R. and Araujo, John F.},
	urldate = {2023-12-05},
	date = {2023},
	pmid = {30252388},
	file = {Printable HTML:/home/vbettachini/storage/Zotero/storage/NRC7SV2Q/NBK526132.html:text/html},
}

@article{blondel_fast_2008,
	title = {Fast unfolding of communities in large networks},
	volume = {2008},
	issn = {1742-5468},
	url = {https://iopscience.iop.org/article/10.1088/1742-5468/2008/10/P10008},
	doi = {10.1088/1742-5468/2008/10/P10008},
	abstract = {We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown ﬁrst by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also veriﬁed on ad hoc modular networks.},
	pages = {P10008},
	number = {10},
	journaltitle = {Journal of Statistical Mechanics: Theory and Experiment},
	shortjournal = {J. Stat. Mech.},
	author = {Blondel, Vincent D and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
	urldate = {2023-12-06},
	date = {2008-10-09},
	langid = {english},
	file = {Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf:/home/vbettachini/storage/Zotero/storage/CZ6BC8DJ/Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf:application/pdf},
}

@article{alexander-bloch_discovery_2012,
	title = {The discovery of population differences in network community structure: New methods and applications to brain functional networks in schizophrenia},
	volume = {59},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911013164},
	doi = {10.1016/j.neuroimage.2011.11.035},
	shorttitle = {The discovery of population differences in network community structure},
	abstract = {The modular organization of the brain network can vary in two fundamental ways. The amount of interversus intra-modular connections between network nodes can be altered, or the community structure itself can be perturbed, in terms of which nodes belong to which modules (or communities). Alterations have previously been reported in modularity, which is a function of the proportion of intra-modular edges over all modules in the network. For example, we have reported that modularity is decreased in functional brain networks in schizophrenia: There are proportionally more inter-modular edges and fewer intra-modular edges. However, despite numerous and increasing studies of brain modular organization, it is not known how to test for differences in the community structure, i.e., the assignment of regional nodes to speciﬁc modules. Here, we introduce a method based on the normalized mutual information between pairs of modular networks to show that the community structure of the brain network is signiﬁcantly altered in schizophrenia, using resting-state {fMRI} in 19 participants with childhood-onset schizophrenia and 20 healthy participants. We also develop tools to show which speciﬁc nodes (or brain regions) have signiﬁcantly different modular communities between groups, a subset that includes right insular and perisylvian cortical regions. The methods that we propose are broadly applicable to other experimental contexts, both in neuroimaging and other areas of network science.},
	pages = {3889--3900},
	number = {4},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Alexander-Bloch, Aaron and Lambiotte, Renaud and Roberts, Ben and Giedd, Jay and Gogtay, Nitin and Bullmore, Ed},
	urldate = {2023-12-09},
	date = {2012-02},
	langid = {english},
	file = {Alexander-Bloch et al. - 2012 - The discovery of population differences in network.pdf:/home/vbettachini/storage/Zotero/storage/RFK32RS7/Alexander-Bloch et al. - 2012 - The discovery of population differences in network.pdf:application/pdf},
}

@article{berry2012aasm,
  title={The AASM manual for the scoring of sleep and associated events},
  author={Berry, Richard B and Brooks, Rita and Gamaldo, Charlene E and Harding, Susan M and Marcus, C and Vaughn, Bradley V and others},
  journal={Rules, Terminology and Technical Specifications, Darien, Illinois, American Academy of Sleep Medicine},
  volume={176},
  pages={2012},
  year={2012}
}

@article{schabus2012fate,
  title={The fate of incoming stimuli during NREM sleep is determined by spindles and the phase of the slow oscillation},
  author={Schabus, Manuel and Dang-Vu, Thien Thanh and Heib, Dominik Philip Johannes and Boly, M{\'e}lanie and Desseilles, Martin and Vandewalle, Gilles and Schmidt, Christina and Albouy, Genevi{\`e}ve and Darsaud, Annabelle and Gais, Steffen and others},
  journal={Frontiers in neurology},
  volume={3},
  pages={40},
  year={2012},
  publisher={Frontiers Research Foundation}
}

@article{boly2012hierarchical,
  title={Hierarchical clustering of brain activity during human nonrapid eye movement sleep},
  author={Boly, M{\'e}lanie and Perlbarg, Vincent and Marrelec, Guillaume and Schabus, Manuel and Laureys, Steven and Doyon, Julien and P{\'e}l{\'e}grini-Issac, M{\'e}lanie and Maquet, Pierre and Benali, Habib},
  journal={Proceedings of the National Academy of Sciences},
  volume={109},
  number={15},
  pages={5856--5861},
  year={2012},
  publisher={National Acad Sciences}
}