\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage[final, nonatbib]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage[spanish, es-tabla]{babel}

\usepackage[pdftex]{graphicx}
\usepackage{subcaption}
\graphicspath{{./graphs/}}

%% biblatex
\usepackage[style = numeric, backend = biber, sorting = none, doi = false, isbn = false, url = true]{biblatex}
% \usepackage[defernumbers = true, style = numeric, backend = biber, sorting = none, doi = false, isbn = false, url = true]{biblatex}
% \usepackage[style = numeric, backend = biber, sorting = none]{biblatex}    % REFERENCIAS como section
\AtEveryBibitem{
    \clearfield{urlyear}
    \clearfield{urlmonth}
} % Do not show the "(visited on <date>)" on the references
\DefineBibliographyStrings{spanish}{}
\usepackage{csquotes}
\addbibresource{./dmcyt.bib}
\renewcommand*{\bibfont}{\fontsize{9}{12}\selectfont}



\title{Procesamiento de imágenes (pre TP1)}

\author{
  Víctor A.~Bettachini\\ %\thanks{Use footnote for providing further information about author (webpage, alternative address)---\emph{not} for acknowledging funding agencies.} \\
  Datamining en ciencia y tecnología 2023\\
  Especialización en Explotación de Datos y Descubrimiento del Conocimiento\\
  \texttt{bettachini@gmail.com}
}


\begin{document}


\maketitle


\begin{abstract}
	Se explican someramente algunos procedimientos para modificar un conjunto de imágenes en baja resolución de flores con métodos provistos por las bibliotecas OpenCV y Clusterimage.
	Contrastar la distribución de la luminancia en cada uno de los tres canales en que se codificó el espacio de color de las imágenes (RGB) resultó insuficiente para discriminar entre especies.
	Por el contrario una descomposición de esta información en componentes principales y un posterior agrupamiento no supervisado es capaz de identificar especies distintas con relativo éxito.
\end{abstract}


% Enunciado
% Se sugiere realizar la entrega en formato latex, pero en este caso va a ser optativo (en el TP ya es obligatorio, sugerimos que lo usen de práctica). Pueden acceder a formatos de distintas conferencias a través de Overleaf, en particular les sugerimos el formato de NeurIPS que es una de las conferencias más importantes en IA.
% Se sugiere un máx de 4 carillas (mín 2), no se debe incluir código a menos que sea algo esencial que hayan desarrollado ustedes (es preferible en este caso incluir el pseudo-código). Aclaración: No vamos a corregir código en la entrega.
% El pre TP es individual.


% \section{Introducción}

\section{Materiales y métodos}

\paragraph{Datos}
210 imágenes de flores acompañados de un listado de las correspondientes especies dentro de una variedad de 10.
Las imágenes en formato png tienen una dimensión de 128 x 128 píxeles espaciales y 3 de color (RGB: rojo, verde y azul).
El conjunto se descargó de una fuente pública \cite{belitskaya_flower_2020}.


\paragraph{Recurso informático} 
Un cuaderno (notebook) Jupyter provisto por los docentes en el sitio web denominado ``Campus'' \cite{kamienkowski_curso_2023} es la plantilla donde se escribió código en lenguaje Python.
Este explotó funciones de las bibliotecas OpenCV (\verb'cv2') y Clustimage para el trabajo con imágenes.
% Se modificó el sendero a los archivos para indicar un directorio en un sistema de archivos local de una computadora local para ejecutarle con mayor velocidad.


\section{Resultados}

\subsection{Preprocesamiento de los datos}
% Cada actividad realizada se describe bajo los titulos que figuran en el enunciado del trabajo práctico publicado en el

% Cargar el dataset y sus respectivas etiquetas. Es importante asegurarse que las imágenes sean comparables en color, valor, rango y tamaño.
\paragraph{Carga del conjunto de datos} 
El método \verb'cv2.imread' carga los canales es azul, verde, rojo (BGR: blue, green, red).
Invirtiendo la carga en un array (arreglo de la biblioteca numpy) se los ordena como RGB con la sentencia \verb'cv2.imread(path[0])[...,::-1]', en este caso para la primer imagen en el directorio al que apunta \verb'path'.
La \hyperref[fg:path0]{figura \ref*{fg:path0}} muestra en colores naturales la imagen generada a partir del array por el método \verb'imshow' de la biblioteca matplotlib.

% Explorar y graﬁcar los subconjuntos de imágenes que representan ﬂores de la misma especie



\subsection{Manipulación de datos}

% Cambiar la intensidad de una de las imágenes en escala de grises, transformarla en una imagen con mucho y otra con poco brillo.
\paragraph{Escala de grises}
Se utilizó la combinación lineal que preserva la luminancia ``perceptual'' de la codificación de color sRGB de la Commission Internationale de l'éclairage en 1931 según el consorcio W3 \cite{noauthor_standard_1996} $
Y_\mathrm{lineal} = 0.2126 R_\mathrm{lineal} + 0.7152 G_\mathrm{lineal} + 0.0722 B_\mathrm{lineal} .
$
La \hyperref[fg:imgGrau]{figura \ref*{fg:imgGrau}} muestra la luminancia obtenida en una escala lineal de grises.
Alternativamente el método \verb'cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)' genera similar producto.
% Esto lo muestran los histogamas de ambas alternativas (ver \hyperref[fg:grayHist]{figura \ref*{fg:grayHist}}).


\paragraph{Brillo}
Aplicar una función lineal 
$
Y_\mathrm{salida} = \alpha Y_\mathrm{entrada} + \beta ,
$
donde $\alpha$ la ganancia controla el contraste y $\beta$ el sesgo controla el brillo modifica el histograma de luminancia \cite{noauthor_opencv_nodate}.
Un \(beta \gg 0\) hace que \(Y_\mathrm{salida}> 255\), pero se le asigna \(255\).
Esto produce saturación (ver figura \hyperref[fg:saturada]{figura \ref*{fg:saturada}}).
Para evitarle se utiliza una ley de potencias
\(
Y_\mathrm{salida} = 255 \left( \frac{Y_\mathrm{entrada}}{255} \right)^\gamma  
\)
conocida como corrección gamma por el exponente utilizado.
Un \(\gamma= 0.4\) redundó en la \hyperref[fg:imgGrau0p4exp]{figura \ref*{fg:imgGrau0p4exp}}, que muestra mayor brillo sin saturación (ver figura \hyperref[fg:brightHist]{figura \ref*{fg:brightHist}}).
Se reduce la luminancia con un \(\gamma >1\), como ejemplifica la \hyperref[fg:imgGrau3p5exp]{figura \ref*{fg:imgGrau3p5exp}} para \(\gamma = 3.5\).

%\begin{figure}
%	\centering
%	\begin{subfigure}[b]{0.48\textwidth}
%		\includegraphics[width= \textwidth]{grayHist}
%		\caption{Escala de grises.}
%		\label{fg:grayHist}
%	\end{subfigure}
%	\begin{subfigure}[b]{0.48\textwidth}
%		\includegraphics[width= \textwidth]{brightHist}
%		\caption{Incremento brillo.}
%		\label{fg:brightHist}
%	\end{subfigure}
%	\caption{Comparación de histogramas.}
%\end{figure}


% Convertir una de las imágenes a blanco y negro (binario). ¿Es la única manera? Si existen otras transformaciones mostrar más de una conversión.
\paragraph{Imagen binarizada}	
Se creó una matriz de ceros de la misma dimensión que la de luminancia.
A los píxeles con valores por sobre la mediana (\verb'statistics.median') se les asigno el valor unidad en la nueva matriz que se muestra en la \hyperref[fg:imgGrau0binarizada]{figura \ref*{fg:imgGrau0binarizada}}






% Recortar una parte signiﬁcativa de la imagen, quedándose sólo con el círculo central de la misma.
\paragraph{Recorte circular}
Se generó un arreglo con tres matrices de ceros sobre las que se copiarían píxeles de la imagen original de cumplirse una condición en función de un radio \(r\) del cuatro del número de columnas.
La condición define un círculo centrado con \((i- i_0)^2 + (j- j_0)^2 < r^2\) siendo \((i,j)\) e \((i_0, j_0)\) filas y columnas del arreglo y sus valores centrales respectivamente.
Aplicando la condición en los tres canales de color se obtuvo el viñetado con un círculo de diámetro mitad del ancho de la imagen que muestra la \hyperref[fg:circle]{figura \ref*{fg:circle}}. 


\begin{figure}
	\centering
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{path0}
		\caption{Original}
		\label{fg:path0}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{imgGrau}
		\caption{Solo luminancia}
		\label{fg:imgGrau}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{saturada}
		\caption{Saturada}
		\label{fg:saturada}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{imgGrau0p4exp}
		\caption{Abrillantada}
		\label{fg:imgGrau0p4exp}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{brightHist}
		\caption{Histograma brillo}
		\label{fg:brightHist}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{imgGrau3p5exp}
		\caption{Oscurecida}
		\label{fg:imgGrau3p5exp}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{imgGrau0binarizada}
		\caption{Binarizada}
		\label{fg:imgGrau0binarizada}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{circle}
		\caption{Viñetado}
		\label{fg:circle}
	\end{subfigure}
	\caption{Procesamientos de la primer imagen en el conjunto de datos. En \hyperref[fg:brightHist]{\ref*{fg:brightHist}} figura en naranja el histograma de luminancia tras incrementar el brillo con una función lineal, en verde tras un ajuste del gamma y en celeste el original.}	
\end{figure}



% Generar dos imágenes random: una imagen mezclando los pixels y otra mezclando partes de diferentes imágenes.

\paragraph{Aleatorizar imagen} 
Copiar píxeles de la imagen original con \verb'imgAzar[i,j,c] = img[ indices[i*j][0], indices[i*j]' dentro de dos ciclos for anidados siendo \((i,j)\) los de una lista aleatorizada produjo una imagen que visualmente muestra tener estructura (ver \hyperref[fg:alea1]{figura \ref*{fg:alea1}}).

La \hyperref[fg:alea2]{figura \ref*{fg:alea2}} muestra en este aspecto un mejor resultado.
Para lograrle se pasaron las valores para cada color en tres vectores y cuyos ordenamientos fueron simultáneamente cambiados al azar.
Luego se reconstruyeron las tres matrices en el orden original.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{alea1}
		\caption{Reordenar índices}
		\label{fg:alea1}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{alea2}
		\caption{Mezclar píxeles}
		\label{fg:alea2}
	\end{subfigure}
	\caption{Aleatorización de la primer imagen en el conjunto de datos a nivel de píxeles individuales. En el caso generado aleatorizando una lista de coordenadas para los píxeles, \hyperref[fg:alea1]{\ref*{fg:alea1}}, se aprecian patrones circulares. Un ordenamiento al azar idéntico para cada canal de color de vectores con la luminancia de cada píxel logró un mejor resultado, que se muestra \hyperref[fg:alea2]{\ref*{fg:alea2}}.
	}
\end{figure}


% Aplicar dos tipos diferentes de ﬁltros sobre una imagen, explique en qué casos conviene usar cada uno.
\paragraph{Filtros} 
Se convoluciona un núcleo (matriz normalizada) con una imagen usando \verb'cv2.filter2D'.
Un núcleo que asigna un promedio con primeros vecinos, \(
\frac{1}{9} \left[ {\begin{array}{ccc}
	1 & 1 & 1 \\
	1 & 1 & 1 \\
	1 & 1 & 1 \\
\end{array} } \right]
\), logró el difuminado que muestra la \hyperref[fg:difuminado]{figura \ref*{fg:difuminado}}.
El efecto opuesto, la agudización que muestra la \hyperref[fg:agudizado]{figura \ref*{fg:agudizado}}, se logró con \(
\left[ {\begin{array}{ccc}
	0 & -1 & 0 \\
	-1 & 5 & -1 \\
	0 & -1 & 0 \\
\end{array} } \right].
\)
La \hyperref[fg:laplaciano]{figura \ref*{fg:laplaciano}} muestra solo los bordes.
Es producto de utilizar el núcleo Laplaciano obtenido con solo restar $1$ al elemento central del anterior \cite{noauthor_opencv_nodate-1}.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{path0}
		\caption{Original}
		\label{fg:original}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{difuminado}
		\caption{Difuminado}
		\label{fg:difuminado}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{agudizado}
		\caption{Agudizado}
		\label{fg:agudizado}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\textwidth}
		\includegraphics[width= \textwidth]{laplaciano}
		\caption{Laplaciano}
		\label{fg:laplaciano}
	\end{subfigure}
	\caption{Filtros aplicados a la primer imagen en el conjunto de datos.}
\end{figure}



% Calcular imagen promedio global y el promedio entre las distintas especies. ¿Se pueden distinguir los promedios? ¿Cómo quedan los promedios si consideran las imágenes en blanco y negro?

\paragraph{Promedio de imágenes} Los promedios de las imágenes por sus 10 etiquetas de especie en la \hyperref[fg:promedios]{figura \ref*{fg:promedios}}) aunque sean diferenciables por inspección directa, potencialmente podrían confundirse.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave0}
		\caption{0}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave1}
		\caption{1}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave2}
		\caption{2}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave3}
		\caption{3}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave4}
		\caption{4}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave5}
		\caption{5}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave6}
		\caption{6}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave7}
		\caption{7}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave8}
		\caption{8}
	\end{subfigure}
	\begin{subfigure}[b]{0.09\textwidth}
		\includegraphics[width= \textwidth]{ave9}
		\caption{9}
	\end{subfigure}
	\caption{El número bajo cada imagen corresponde a la etiqueta de especie. La imagen es producto de promediar todas las de idéntica etiqueta.}
	\label{fg:promedios}
\end{figure}



\subsection{Búsqueda de \emph{features}}

% Analizar las distribuciones de valores de pixels por cada especie. ¿Se puede distinguir una especie en algún rango de color?
\paragraph{Distribuciones por especie} La \hyperref[fg:promediosBox]{figura \ref*{fg:promediosBox}}) muestra que algunas especies pueden diferenciarse entre sí viendo un color en particular, pero en ningún caso entre todas.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\includegraphics[width= \textwidth]{rot}
		\caption{Rojo}
		\label{fg:rot}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\textwidth}
		\includegraphics[width= \textwidth]{grün}
		\caption{Verde}
		\label{fg:grün}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\textwidth}
		\includegraphics[width= \textwidth]{blau}
		\caption{Azul}
		\label{fg:blau}
	\end{subfigure}
	\caption{Distribución de colores por etiqueta de especie.}
	\label{fg:promediosBox}
\end{figure}



% Realizar una inspección de las componentes principales del dataset y analizar si se pueden identiﬁcar las especies en esta representación.

\paragraph{Análisis de componentes principales}
Del conjunto de imágenes se obtuvo una centena de componentes principales con el método \verb'extract_feat' de la biblioteca Clustimage \cite{taskesen_pca_2020}.
Los parámetros por defecto de \verb`fit_transform` produjeron 6 agrupamientos (clusters) por el procedimiento \emph{aglomerativo} (en oposición a \emph{kmeans} o \emph{dbscan}) evaluando el coeficiente de \emph{silhouette} de una métrica \emph{euclídea} enlazando (linkage) por \emph{ward} \cite{noauthor_api_nodate}.
La \hyperref[fg:tsne]{figura \ref*{fg:tsne}}) es la representación \emph{t-distributed stochastic neighbor embedding (t-SNE)} que coloriza las coordenadas en la dos más significativas componentes principales para cada imagen según en que categoría quedaron agrupadas.
Una inspección visual de los promedios de cada agrupación sugiere que pueden identificarse especies distintas.
En lo generado por \verb'cl.dendrogram' no pudo identificarse una distancia que redundaría en el mismo número de agrupamientos que especies en el conjunto de datos.


% \section{Discusión}

\begin{figure}
  \centering
  \includegraphics[width= 0.8\linewidth]{tsne}
  \caption{Los colores codifican el agrupamiento para cada imagen en el espacio de las dos principales componentes principales del conjunto (t-SNE plot). Los colores promedio no se corresponden con los reales pues está enrocado el azul con el rojo y por tanto no coinciden visualmente con ningún caso de la \hyperref[fg:promediosBox]{figura \ref*{fg:promediosBox}}.}
	\label{fg:tsne}
\end{figure}


\printbibliography[title= Referencias, heading=bibintoc]

\end{document}
